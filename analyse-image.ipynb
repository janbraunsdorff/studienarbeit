{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(img_path,  size_target=256):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    size_target = 450\n",
    "    img = cv2.resize(img, (size_target, size_target), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    lab_planes = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    lab = cv2.merge(lab_planes)\n",
    "    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    x = y = (size_target - 299) // 2\n",
    "\n",
    "    h = w = 299\n",
    "    img = bgr[y:y + h, x:x + w]\n",
    "\n",
    "    arr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    t_img = torch.tensor(arr).unsqueeze(0).float()\n",
    "\n",
    "    t_img /= 255.0\n",
    "\n",
    "\n",
    "    return t_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/Users/janbraunsdorff/Studienarbeit-projekt/data'\n",
    "path_to_validation_annotation = path_to_data + \"/validation.csv\"\n",
    "path_to_training_annotation = path_to_data + \"/training.csv\"\n",
    "path_to_validatoin_data = path_to_data + '/boneage-validation-dataset/'\n",
    "path_to_training_data = path_to_data + '/boneage-training-dataset/'\n",
    "path = path_to_data + '/pickel/v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "df_trainig = pd.read_csv(path_to_training_annotation)\n",
    "for index, row in df_trainig.iterrows():\n",
    "    img = processImages(path_to_training_data + str(row[0]) + \".png\")\n",
    "    count += torch.mean(img).item()\n",
    "    if index % 200 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = count / float(len(df_trainig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2772987272627915"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n"
     ]
    }
   ],
   "source": [
    "var = 0\n",
    "for index, row in df_trainig.iterrows():\n",
    "    img = processImages(path_to_training_data + str(row[0]) + \".png\")\n",
    "    var += math.pow(torch.mean(img).item() - mean, 2) *  0.003921568627\n",
    "\n",
    "    if index % 200 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = math.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5228018736810739, 0.2772987272627915)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.4454, -0.3408, -0.2363, -0.1317, -0.0272,  0.0774,  0.1820,  0.2865,\n",
       "         0.3911,  0.4956,  0.6002])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "torch.Tensor([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])  * (std / 0.5) + (mean - 0.5) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}